# Check the classes in the target variable
print("\nClass distribution in y:")
print(y.value_counts())

# If only one class is present, adjust the threshold to balance the classes
if y.nunique() == 1:
    print("\nWarning: Only one class detected. Adjusting the threshold...")
    threshold = df_processed['CO(GT)'].quantile(0.5)  # Use the median as a new threshold
    df_processed['CO_Class'] = (df_processed['CO(GT)'] > threshold).astype(int)
    y = df_processed['CO_Class']  # Redefine y with the new threshold

# Verify the class distribution after adjustment
print("\nClass distribution after adjustment:")
print(y.value_counts())

# Re-split the data
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Logistic Regression
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

log_reg_model = LogisticRegression(max_iter=1000, random_state=42)
log_reg_model.fit(X_train, y_train)  # Train the model

# Predictions
y_pred = log_reg_model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"\nAccuracy: {accuracy:.2f}")

# Confusion Matrix
conf_matrix = confusion_matrix(y_test, y_pred)
print("\nConfusion Matrix:")
print(conf_matrix)

# Classification Report
class_report = classification_report(y_test, y_pred)
print("\nClassification Report:")
print(class_report)

# Visualize the Confusion Matrix
import seaborn as sns
import matplotlib.pyplot as plt

sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=["Below Threshold", "Above Threshold"],
            yticklabels=["Below Threshold", "Above Threshold"])
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()
